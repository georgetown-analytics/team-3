{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Ingestion\n",
    "\n",
    "- Data is read in from csv files\n",
    "- Data is grouped by month, quarter and year from 2018 t0 2022\n",
    "\n",
    "The data is grouped as follows\n",
    "\n",
    "| file name             | Description                                    |\n",
    "|-----------------------|------------------------------------------------|\n",
    "| flight_data_YYYYMM    | Ex: flight_data_202208 is data for August 2022 |\n",
    "| flight_data_Y20YY     | Ex: flight_data_Y2021 is data for 2021         |\n",
    "| flight_data_Y20182022 | Data from 2018 - 2022                          |\n",
    "\n",
    "\n",
    "----------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flight Data by Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load 2022 data groupby month ##\n",
    "##################################\n",
    "\n",
    "###JANUARY 2022###\n",
    "df_012022 = pd.read_csv(\"../../data/eda/flights/flight_data_2022/flight_data_202201.zip\", low_memory=False)\n",
    "\n",
    "###JUNE 2022###\n",
    "#df_062022 = pd.read_csv(\"../../data/eda/flights/flight_data_2022/flight_data_202206.zip\", low_memory=False)\n",
    "\n",
    "###AUGUST 2020###\n",
    "#df_082022 = pd.read_csv(\"../../data/eda/flights/flight_data_2022/flight_data_202208.zip\", low_memory=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flight Data 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merge data groupby year ##\n",
    "##################################\n",
    "# merging 2022 csv files\n",
    "rpath2022 = \"../../data/eda/flights/flight_data_2022/flight_data_2022*.zip\"\n",
    "all_files_2022 = glob.glob(rpath2022, recursive=True)\n",
    "\n",
    "[f for f in all_files_2022]\n",
    "\n",
    "#df = pd.concat((pd.read_csv(f, low_memory=False) for f in all_files_2022), ignore_index=True)\n",
    "#df.to_csv(\"../../data/eda/flights/flight_data_Y2022/flight_data_2022.csv.zip\",compression=\"zip\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flight Data 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merge data groupby year ##\n",
    "##################################\n",
    "# merging 2021 csv files\n",
    "rpath2021 = \"../../data/eda/flights/flight_data_2021/flight_data_2021*.zip\"\n",
    "all_files_2021 = glob.glob(rpath2021, recursive=True)\n",
    "\n",
    "[f for f in all_files_2021]\n",
    "\n",
    "df = pd.concat((pd.read_csv(f, low_memory=False) for f in all_files_2021), ignore_index=True)\n",
    "df.to_csv(\"../../data/eda/flights/flight_data_Y2021/flight_data_2021.csv.zip\",compression=\"zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merge data groupby year ##\n",
    "##################################\n",
    "# merging 2020 csv files\n",
    "rpath2020 = \"../../data/eda/flights/flight_data_2020/flight_data_2020*.zip\"\n",
    "all_files_2020 = glob.glob(rpath2020, recursive=True)\n",
    "\n",
    "[f for f in all_files_2020]\n",
    "\n",
    "df = pd.concat((pd.read_csv(f, low_memory=False) for f in all_files_2020), ignore_index=True)\n",
    "df.to_csv(\"../../data/eda/flights/flight_data_Y2020/flight_data_2020.csv.zip\",compression=\"zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../data/eda/flights/flight_data_2019\\\\flight_data_201901.zip',\n",
       " '../../data/eda/flights/flight_data_2019\\\\flight_data_201902.zip',\n",
       " '../../data/eda/flights/flight_data_2019\\\\flight_data_201903.zip',\n",
       " '../../data/eda/flights/flight_data_2019\\\\flight_data_201904.zip',\n",
       " '../../data/eda/flights/flight_data_2019\\\\flight_data_201905.zip',\n",
       " '../../data/eda/flights/flight_data_2019\\\\flight_data_201906.zip',\n",
       " '../../data/eda/flights/flight_data_2019\\\\flight_data_201907.zip',\n",
       " '../../data/eda/flights/flight_data_2019\\\\flight_data_201908.zip',\n",
       " '../../data/eda/flights/flight_data_2019\\\\flight_data_201909.zip',\n",
       " '../../data/eda/flights/flight_data_2019\\\\flight_data_201910.zip',\n",
       " '../../data/eda/flights/flight_data_2019\\\\flight_data_201911.zip',\n",
       " '../../data/eda/flights/flight_data_2019\\\\flight_data_201912.zip']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Merge data groupby year ##\n",
    "##################################\n",
    "# merging 2019 csv files\n",
    "rpath2019 = \"../../data/eda/flights/flight_data_2019/flight_data_2019*.zip\"\n",
    "all_files_2019 = glob.glob(rpath2019, recursive=True)\n",
    "\n",
    "[f for f in all_files_2019]\n",
    "\n",
    "df = pd.concat((pd.read_csv(f, low_memory=False) for f in all_files_2019), ignore_index=True)\n",
    "df.to_csv(\"../../data/eda/flights/flight_data_Y2019/flight_data_2019.csv.zip\",compression=\"zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merge data groupby year ##\n",
    "##################################\n",
    "# merging 2018 csv files\n",
    "rpath2018 = \"../../data/eda/flights/flight_data_2018/flight_data_2018*.zip\"\n",
    "all_files_2018 = glob.glob(rpath2018, recursive=True)\n",
    "\n",
    "[f for f in all_files_2018]\n",
    "\n",
    "df = pd.concat((pd.read_csv(f, low_memory=False) for f in all_files_2018), ignore_index=True)\n",
    "df.to_csv(\"../../data/eda/flights/flight_data_Y2018/flight_data_2018.csv.zip\",compression=\"zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_flights_2022 = pd.read_csv(\"../../data/eda/flights/flight_data_Y2022/flight_data_2022.csv.zip\", low_memory=False)\n",
    "## df_flights_2022.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined Flight data 2018 - 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: out of memory",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [3], line 7\u001b[0m\n\u001b[0;32m      3\u001b[0m all_files_2018_2022 \u001b[39m=\u001b[39m glob\u001b[39m.\u001b[39mglob(rpath_2018_2022, recursive\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m      5\u001b[0m [f \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m all_files_2018_2022]\n\u001b[1;32m----> 7\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mconcat((pd\u001b[39m.\u001b[39;49mread_csv(f, low_memory\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m) \u001b[39mfor\u001b[39;49;00m f \u001b[39min\u001b[39;49;00m all_files_2018_2022), ignore_index\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m      8\u001b[0m df\u001b[39m.\u001b[39mto_csv(\u001b[39m\"\u001b[39m\u001b[39m../../data/eda/flights/flight_data_Y20182022/flight_data_2018_2022.csv.zip\u001b[39m\u001b[39m\"\u001b[39m,compression\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mzip\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\jenni\\.virtualenvs\\team-3-N2NXnkel\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jenni\\.virtualenvs\\team-3-N2NXnkel\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:368\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[39m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, allowed_args\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mobjs\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m    147\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconcat\u001b[39m(\n\u001b[0;32m    148\u001b[0m     objs: Iterable[NDFrame] \u001b[39m|\u001b[39m Mapping[HashableT, NDFrame],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    157\u001b[0m     copy: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    158\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[0;32m    159\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    160\u001b[0m \u001b[39m    Concatenate pandas objects along a particular axis.\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[39m    1   3   4\u001b[39;00m\n\u001b[0;32m    367\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 368\u001b[0m     op \u001b[39m=\u001b[39m _Concatenator(\n\u001b[0;32m    369\u001b[0m         objs,\n\u001b[0;32m    370\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[0;32m    371\u001b[0m         ignore_index\u001b[39m=\u001b[39;49mignore_index,\n\u001b[0;32m    372\u001b[0m         join\u001b[39m=\u001b[39;49mjoin,\n\u001b[0;32m    373\u001b[0m         keys\u001b[39m=\u001b[39;49mkeys,\n\u001b[0;32m    374\u001b[0m         levels\u001b[39m=\u001b[39;49mlevels,\n\u001b[0;32m    375\u001b[0m         names\u001b[39m=\u001b[39;49mnames,\n\u001b[0;32m    376\u001b[0m         verify_integrity\u001b[39m=\u001b[39;49mverify_integrity,\n\u001b[0;32m    377\u001b[0m         copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m    378\u001b[0m         sort\u001b[39m=\u001b[39;49msort,\n\u001b[0;32m    379\u001b[0m     )\n\u001b[0;32m    381\u001b[0m     \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39mget_result()\n",
      "File \u001b[1;32mc:\\Users\\jenni\\.virtualenvs\\team-3-N2NXnkel\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:422\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[1;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[0;32m    420\u001b[0m     objs \u001b[39m=\u001b[39m [objs[k] \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m keys]\n\u001b[0;32m    421\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 422\u001b[0m     objs \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(objs)\n\u001b[0;32m    424\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(objs) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    425\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo objects to concatenate\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn [3], line 7\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      3\u001b[0m all_files_2018_2022 \u001b[39m=\u001b[39m glob\u001b[39m.\u001b[39mglob(rpath_2018_2022, recursive\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m      5\u001b[0m [f \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m all_files_2018_2022]\n\u001b[1;32m----> 7\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat((pd\u001b[39m.\u001b[39;49mread_csv(f, low_memory\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m) \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m all_files_2018_2022), ignore_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m      8\u001b[0m df\u001b[39m.\u001b[39mto_csv(\u001b[39m\"\u001b[39m\u001b[39m../../data/eda/flights/flight_data_Y20182022/flight_data_2018_2022.csv.zip\u001b[39m\u001b[39m\"\u001b[39m,compression\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mzip\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\jenni\\.virtualenvs\\team-3-N2NXnkel\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jenni\\.virtualenvs\\team-3-N2NXnkel\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jenni\\.virtualenvs\\team-3-N2NXnkel\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\jenni\\.virtualenvs\\team-3-N2NXnkel\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n\u001b[0;32m    610\u001b[0m \u001b[39mwith\u001b[39;00m parser:\n\u001b[1;32m--> 611\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\u001b[39m.\u001b[39;49mread(nrows)\n",
      "File \u001b[1;32mc:\\Users\\jenni\\.virtualenvs\\team-3-N2NXnkel\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1778\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1771\u001b[0m nrows \u001b[39m=\u001b[39m validate_integer(\u001b[39m\"\u001b[39m\u001b[39mnrows\u001b[39m\u001b[39m\"\u001b[39m, nrows)\n\u001b[0;32m   1772\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1773\u001b[0m     \u001b[39m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[0;32m   1774\u001b[0m     (\n\u001b[0;32m   1775\u001b[0m         index,\n\u001b[0;32m   1776\u001b[0m         columns,\n\u001b[0;32m   1777\u001b[0m         col_dict,\n\u001b[1;32m-> 1778\u001b[0m     ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mread(  \u001b[39m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[0;32m   1779\u001b[0m         nrows\n\u001b[0;32m   1780\u001b[0m     )\n\u001b[0;32m   1781\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m   1782\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\jenni\\.virtualenvs\\team-3-N2NXnkel\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:235\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    232\u001b[0m         data \u001b[39m=\u001b[39m _concatenate_chunks(chunks)\n\u001b[0;32m    234\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 235\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reader\u001b[39m.\u001b[39;49mread(nrows)\n\u001b[0;32m    236\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[0;32m    237\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_first_chunk:\n",
      "File \u001b[1;32mc:\\Users\\jenni\\.virtualenvs\\team-3-N2NXnkel\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:790\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\jenni\\.virtualenvs\\team-3-N2NXnkel\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:883\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\jenni\\.virtualenvs\\team-3-N2NXnkel\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:1973\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: out of memory"
     ]
    }
   ],
   "source": [
    "rpath_2018_2022 = \"../../data/eda/flights/flight_data_Y*/flight_data_*.zip\"\n",
    "\n",
    "all_files_2018_2022 = glob.glob(rpath_2018_2022, recursive=True)\n",
    "\n",
    "[f for f in all_files_2018_2022]\n",
    "\n",
    "df = pd.concat((pd.read_csv(f, low_memory=False) for f in all_files_2018_2022), ignore_index=True)\n",
    "df.to_csv(\"../../data/eda/flights/flight_data_Y20182022/flight_data_2018_2022.csv.zip\",compression=\"zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('team-3-N2NXnkel')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "13b707afe647235fabbd8fa9a50cb628621b6b26172b2c2a7128d664447ee1d0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
